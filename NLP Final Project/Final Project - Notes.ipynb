{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project - Notes + Annotated Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Methodology followed: **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. X - Vectorize the data using ngram_range: to combine unigrams, bigrams, trigrams\n",
    "2. y - The sentiment labels - Negative, Neutral and Positive\n",
    "3. Make a train test split based on the X and y defined above.\n",
    "    - Setting 25% as the Test data and 75% as training data\n",
    "    - Setting random state to prevent data from changing\n",
    "4. Initialize models (Most models were initialized on default parameters)\n",
    "5. Predict values based on these models\n",
    "6. Calculate Metrics:\n",
    "    - Accuracy\n",
    "    - F1-Score\n",
    "7. Compare models based on the metrics\n",
    "8. Apply grid search on the best model\n",
    "9. Implement cross_validation_score from sklearn for the best model using the parameters found by GridSearch.\n",
    "10. Build and visualize confusion matrix for the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reason for using SVM:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It can be used where the other models cannot perform as required: \n",
    "    - Because there was some degree of class imbalance in my dataset.\n",
    "- Other advantages i considered:\n",
    "    - It doesn't require a particular type of distribution.\n",
    "    - Ablity to make use of non-linear kernels.\n",
    "    - Doesn't suffer from multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reason for using Ensemble Classifiers:** : My goal was to improve accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other advantages:\n",
    "\n",
    "- Its extremely randomized version of DecisionTreeClassifier.\n",
    "- It helps to tackle the variance in the training data.\n",
    "- They more robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reason for using Cross Validation:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needed to determine how well the model will perform for random test samples. i.e. it is used for model evaluation.\n",
    "\n",
    "- It removes some of the data before the training of the model begins. And uses the removed data to test the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Annotating the ExtraTreesClassifier **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ExtraTreesClassifier is a child class of ForestClassifier that: \n",
    "\n",
    "- Is a base class for forest of trees-based classifiers.\n",
    "- It computes different parameters such as:\n",
    "    - Base_estimator - based on tree-based classifier.\n",
    "    - n_estimators - the number of trees.\n",
    "    - estimator_params - pass in estimator parameters.\n",
    "    - bootstrap=False - whether to pass in boostrap samples or not.\n",
    "    - oob_score=False - to check whether to use out of back score.\n",
    "    - n_jobs=1 - number of parallel processes to run \n",
    "    - random_state=None - if this is set then the random numbers don't change on iterations.\n",
    "    - verbose=0 - to set how verbose the tree building process should be.\n",
    "    - warm_start=False - to reuse previous fits if this is set\n",
    "    - class_weight=None - by default all classes have same weight but this can be changed by altering this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Fit and Predict method of ExtraTreesClassifier : Source: Scikit Learn ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Fit, fit_transform and transform ** methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(self, X, y=None, sample_weight=None):\n",
    "    \"\"\"Fit estimator.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like or sparse matrix, shape=(n_samples, n_features)\n",
    "        The input samples. Use ``dtype=np.float32`` for maximum\n",
    "        efficiency. Sparse matrices are also supported, use sparse\n",
    "        ``csc_matrix`` for maximum efficiency.\n",
    "    Returns\n",
    "    -------\n",
    "    self : object\n",
    "        Returns self.\n",
    "    \"\"\"\n",
    "    # It calls the fit_transform function from the same class that takes an input of\n",
    "    # X: Features and y: labels, also sets the sample weight as per users input\n",
    "    self.fit_transform(X, y, sample_weight=sample_weight)\n",
    "    return self\n",
    "\n",
    "def fit_transform(self, X, y=None, sample_weight=None):\n",
    "    \"\"\"Fit estimator and transform dataset.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like or sparse matrix, shape=(n_samples, n_features)\n",
    "        Input data used to build forests. Use ``dtype=np.float32`` for\n",
    "        maximum efficiency.\n",
    "    Returns\n",
    "    -------\n",
    "    X_transformed : sparse matrix, shape=(n_samples, n_out)\n",
    "        Transformed dataset.\n",
    "    \"\"\"\n",
    "    # ensure_2d=False because there are actually unit test checking we fail\n",
    "    # for 1d.\n",
    "    X = check_array(X, accept_sparse=['csc'], ensure_2d=False)\n",
    "    \n",
    "    # Check if the input X is sparse\n",
    "    if issparse(X):\n",
    "        \n",
    "        # If yes then Pre-sort indices to avoid that each individual tree of the\n",
    "        # Sort the indices of X.\n",
    "        X.sort_indices()\n",
    "    \n",
    "    # Checks whether the random state is true or false and updates a varaible \n",
    "    # rnd based on that.\n",
    "    rnd = check_random_state(self.random_state)\n",
    "    \n",
    "    # Create samples that have a uniformly distribution and are\n",
    "    # Distrubuted over the half-open interval [low, high]\n",
    "    y = rnd.uniform(size=X.shape[0])\n",
    "    \n",
    "    # Call the superclass to avoid explicitly refer the base class\n",
    "    super(RandomTreesEmbedding, self).fit(X, y, sample_weight=sample_weight)\n",
    "    \n",
    "    # Call the OneHotEncoder function that:\n",
    "    # is required for feeding categorical data.\n",
    "    # it creates a sparse matrix based on the input of matrix of integers\n",
    "    self.one_hot_encoder_ = OneHotEncoder(sparse=self.sparse_output)\n",
    "    \n",
    "    # Apply X to fit transform of one hot encoder and return it\n",
    "    return self.one_hot_encoder_.fit_transform(self.apply(X))\n",
    "\n",
    "def transform(self, X):\n",
    "    \"\"\"Transform dataset.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like or sparse matrix, shape=(n_samples, n_features)\n",
    "        Input data to be transformed. Use ``dtype=np.float32`` for maximum\n",
    "        efficiency. Sparse matrices are also supported, use sparse\n",
    "        ``csr_matrix`` for maximum efficiency.\n",
    "    Returns\n",
    "    -------\n",
    "    X_transformed : sparse matrix, shape=(n_samples, n_out)\n",
    "        Transformed dataset.\n",
    "    \"\"\"\n",
    "    # Apply X to transform of one hot encoder and return it \n",
    "    return self.one_hot_encoder_.transform(self.apply(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(self, X):\n",
    "    \"\"\"Predict class for X.\n",
    "    The predicted class of an input sample is a vote by the trees in\n",
    "    the forest, weighted by their probability estimates. That is,\n",
    "    the predicted class is the one with highest mean probability\n",
    "    estimate across the trees.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
    "       The input samples. Internally, it will be converted to\n",
    "       ``dtype=np.float32`` and if a sparse matrix is provided\n",
    "       to a sparse ``csr_matrix``.\n",
    "    Returns\n",
    "    -------\n",
    "    y : array of shape = [n_samples] or [n_samples, n_outputs]\n",
    "       The predicted classes.\n",
    "    \"\"\"\n",
    "    # Calling the predict_proba() function from the class and computing the\n",
    "    # the probabilities of X and saving it in proba.\n",
    "    proba = self.predict_proba(X)\n",
    "    \n",
    "    # Checking if number of outputs is equal to 1\n",
    "    # Number of outputs is the number of outputs when fit is used.\n",
    "    if self.n_outputs_ == 1:\n",
    "        \n",
    "        # If it is then we are returning the indices of the maximum values along the axis.\n",
    "        return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n",
    "    else:\n",
    "        \n",
    "        # Setting the number of samples equal to number of observations in the variable \n",
    "        # proba, which contains the probabilities of X.\n",
    "        n_samples = proba[0].shape[0]\n",
    "        \n",
    "        # Define predictions as an array of zeros of the same size as the number of samples\n",
    "        predictions = np.zeros((n_samples, self.n_outputs_))\n",
    "        \n",
    "        # Loop over the range of n_outputs \n",
    "        for k in range(self.n_outputs_):\n",
    "            \n",
    "            # for every row at k'th column calculate the prediction and update the prediction array\n",
    "            predictions[:, k] = self.classes_[k].take(np.argmax(proba[k],axis=1),axis=0)\n",
    "        \n",
    "        # Return the predictions\n",
    "        return predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
